{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to management optimization (under uncertainty)\n",
    "\n",
    "So far in these awesome tutorial notebooks, we have been focused on estimating uncertain model inputs (i.e. parameters), estimating the uncertainty in these inputs, and propagating the uncertainty in these inputs to important model outputs (i.e. predictions), namely unmeasured groundwater levels and surface-water/groundwater exchange fluxes during (unseen) dry conditions.  Now we are going to go the next level and start to use the model in an entirely new way:  rather than estimating the uncertainty in important model outputs during unseen dry conditions, what if we \"flip the script\" and instead ask the question \"how much groundwater can we extract before the surface-water/groundwater exchange flux reaches an unacceptable value\"?  And what if we augment the question with something even more exciting: \"...at the 95% confidence level\"?  OOOhhh that sounds so nice!  \n",
    "\n",
    "Let's begin our journey with some terminology:\n",
    "\n",
    "- __parameter__: an uncertain model input whose value we want to estimate and whose uncertainty we want to propagate to important model outputs.\n",
    "- __decision variable__: a model input whose value can be \"controlled\" by human activity.  For example, groundwater extraction rates or surface-water structure operations.  Like a parameter, a decision variable also influences important model outputs.\n",
    "- __constraint__: an uncertain model output whose real-world equivalent value has a range of \"undesired values\".  In management optimization, \"constraints\" are typically \"inequality\" constraints, meaning the constraint can take any value other than the undesired values.  Think \"surface-water/groundwater exchange flux must be greater than XXX to support ecological flows\".\n",
    "- __chance constraint__: given that the relation between decision variables and constraints must be evaluated with the model, constraints are \"uncertain\" in exactly the same way the \"predictions\" or \"forecasts\" are uncertain. Therefore, it only makes sense that we include \"uncertainty\" in the management optimization process.  One way to do this is with \"chance constraints\", where we include uncertainty in the constraints.  However, most management optimization algorithms do not tolerate a statistical distribution of constraint values - they need a single value.  So we will use the concept of \"risk\" to identify a scalar constraint value from the statistical constraint distribution - a scalar value that implicitly represents the underlying uncertainty.\n",
    "- __risk__: a value that ranges for 0.0 (risk tolerant) to 1.0 (risk averse). When you see \"risk\" think \"reliability\". The more risk averse you are, the more \"uncertainty\" will cost you in the final optimization solution.\n",
    "- __objective function__: a (potentially nonlinear) function of the decision variables that is to be maximized or minimized, depending on the problem.  For example, in the case of groundwater extraction, the objective is to maximize the volume of groundwater extracted (subject to not violating the constraints).\n",
    "    \n",
    "\n",
    "Whew!  Ok, lets see some of this in practice.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Admin\n",
    "\n",
    "Start off with the usual loading of dependencies and preparing model and PEST files. We will be continuing to work with the modified-Freyberg model (see [\"freyberg intro to model\"](../part0_02_intro_to_freyberg_model/intro_freyberg_model.ipynb) notebook), and the high-dimensional PEST dataset prepared in the [\"freyberg pstfrom pest setup\"](../part2_01_pstfrom_pest_setup/freyberg_pstfrom_pest_setup.ipynb)\" and [\"observation and weights\"](../part2_02_obs_and_weights/freyberg_obs_and_weights.ipynb) notebooks. \n",
    "\n",
    "For the purposes of this notebook, you do not require familiarity with previous notebooks (but it helps...). \n",
    "\n",
    "Simply run the next few cells by pressing `shift+enter`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "font = {'size'   : 10}\n",
    "import matplotlib\n",
    "matplotlib.rc('font', **font)\n",
    "import matplotlib.pyplot as plt;\n",
    "import shutil\n",
    "import psutil\n",
    "\n",
    "import sys\n",
    "import pyemu\n",
    "import flopy\n",
    "assert \"dependencies\" in flopy.__file__\n",
    "assert \"dependencies\" in pyemu.__file__\n",
    "sys.path.insert(0,\"..\")\n",
    "import herebedragons as hbd\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To maintain continuity in the series of tutorials, we we use the PEST-dataset prepared in the [\"observation and weights\"](../part2_02_obs_and_weights/freyberg_obs_and_weights.ipynb) tutorial. Run the next cell to copy the necessary files across. Note that you will need to run the previous notebooks in the correct order beforehand.\n",
    "\n",
    "Specify the path to the PEST dataset template folder. Recall that we will prepare our PEST dataset files in this folder, keeping them separate from the original model files. Then copy across pre-prepared model and PEST files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify the temporary working folder\n",
    "t_d = os.path.join('freyberg6_template')\n",
    "if os.path.exists(t_d):\n",
    "    shutil.rmtree(t_d)\n",
    "\n",
    "org_t_d = os.path.join(\"..\",\"part2_02_obs_and_weights\",\"freyberg6_template\")\n",
    "if not os.path.exists(org_t_d):\n",
    "    raise Exception(\"you need to run the '/part2_02_obs_and_weights/freyberg_obs_and_weights.ipynb' notebook\")\n",
    "\n",
    "shutil.copytree(org_t_d,t_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst_path = os.path.join(t_d, 'freyberg_mf6.pst')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the PEST Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "OK. We can now get started.\n",
    "\n",
    "Load the PEST control file as a `Pst` object. We are going to use the PEST control file that was created in the [\"observation and weights\"](../part2_02_obs_and_weights/freyberg_obs_and_weights.ipynb)\" tutorial. This control file has observations with weights equal to the inverse of measurement noise (**not** weighted for visibility!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst = pyemu.Pst(pst_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if obs&weights notebook has been run\n",
    "if not pst.observation_data.observed.sum()>0:\n",
    "    raise Exception(\"You need to run the '/part2_02_obs_and_weights/freyberg_obs_and_weights.ipynb' notebook\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a quick parameter summary table as a reminder of what we have in our control file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.write_par_summary_table(filename=\"none\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that our parameterisation is quite comprehensive, with pilot points and grid based (e.g. cell-by-cell) parameters. \n",
    "\n",
    "Let's recall how many adjustable parameters we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.npar_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the previously-calibrated parameter values\n",
    "\n",
    "An obvious linkage to the data assimilation process is to use the mean posterior parameter values in the control file, so that when we adjust decision variables, the simulated response at constraints is evaluated with these parameters. We can do this easy-peasy with python:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glm_dir = os.path.join(\"..\",\"part2_04_glm\",\"master_glm_2\")\n",
    "if os.path.exists(glm_dir):\n",
    "    par_file = os.path.join(glm_dir,\"freyberg_pp.par\")\n",
    "    if os.path.exists(par_file):\n",
    "        pst.parrep(par_file)\n",
    "    else:\n",
    "        print(\"parfile '{0}' not found, using prior mean (i.e. existing) parameter values\".format(par_file))\n",
    "else:\n",
    "    print(\"glm_dir '{0}' not found, using prior mean (i.e. existing) parameter values\".format(glm_dir))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving from DA/UA to OPT: decision variables\n",
    "\n",
    "As previously discussed, we are now moving away from the data assimilation (DA) and uncertainty analysis (UA) focus to one of management optimization.  Fortunately for you, we have been planning this journey all along and have included all the necessary pieces for management optimization with in the PEST interface we have been using - what?!  How can this be?! Well, for starters, we have been estimating uncertain historical and future groundwater extraction rates (the `WEL` package \"flux\" quantities). While it is obviously important to account for this important source of model input uncertainty, these same \"parameters\" can also be recast as \"decision variables\" - they are one in the same, depending on the analysis you are interested in!\n",
    "\n",
    "Side note - all jokes aside, it can be helpful to consider up-front what the modelling workflows' end goal is. e.g., are you going to be dealing with an optimization problem? Then it is useful to include parameters for decision variables (and observations for constraints and so on) from the start. That being said, it is entirely feasible to splice these things in at a later stage if you really need to.\n",
    "\n",
    "Let's examine these important model inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = pst.parameter_data\n",
    "# slect only welgrd parameters\n",
    "wpar = par.loc[par.parnme.str.contains(\"welgrd\"),:]\n",
    "# take a peak\n",
    "wpar.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the \"grid-scale\" well flux parameters are just the thing we are wanting to use as decision variables.  But - and this is important - we want to only optimize _future_ water use,  subject to _future_ surface-water/groundwater exchange constraints.  This means we want to only treat \"future\" water use as decision variables, where \"future\" refers to stress periods 13 thru 25 (remember all that from the previous notebooks?).  So we want to __fix__ all \"parameters\", except the grid-scale well flux parameters for stress periods 13 thru 25.  \n",
    "\n",
    "The `inst` metadata gives us a zero-based stress period tag (lucky us!):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpar.loc[:,\"inst\"] = wpar.inst.astype(int)\n",
    "#par.loc[:,\"partrans\"] = \"fixed\"\n",
    "future_wpar_names = wpar.loc[wpar.inst >= 13,\"parnme\"]\n",
    "# take a peak\n",
    "future_wpar_names.values[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are going to do some trickery to help us use these \"parameters\" as decision variables.\n",
    "\n",
    "The changes we need to implement are mostly related to the bounds and transform. We want to be able to \"turn off\" a given extraction well, so we want its transform to be `none` and we want it's lower bound to 0.0 (remember these are actually multiplier parameters). Why `none`? Because log-transformed parameters cannot be zero.\n",
    "\n",
    "Lastly, we also need to put these parameters into their own dedicated parameter group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the transform\n",
    "par.loc[future_wpar_names,\"partrans\"] = \"none\"\n",
    "# change the initial value and bounds\n",
    "par.loc[future_wpar_names,\"parlbnd\"] = 0.0\n",
    "par.loc[future_wpar_names,\"parval1\"] = 0.0\n",
    "par.loc[future_wpar_names,\"parubnd\"] = 6.0\n",
    "# add these paremters to the \"decvars\" parameter group\n",
    "par.loc[future_wpar_names,\"pargp\"] = \"decvars\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to set just one little \"++\" arg:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"opt_dec_var_groups\"] = \"decvars\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving from DA/UQ to OPT: objective function\n",
    "\n",
    "Its an unfortunate naming issue, but the \"objective function\" we have talked about for many, many notebooks will now mean something completely different.  \n",
    "\n",
    "As a quick aside, its important to realize that the reason we talk about the \"objective function\" in the previous  -  and throughout the PEST world -  is because all of the PEST and PEST++ tools for parameter estimation/data assimilation/uncertainty quantification are in fact optimization algorithms that have been repurposed for these analyses.  But, unlike before, where we had to worry about overfitting, parameter plausibility, etc, we are now free to adjust decision variables in any pattern we like and we are free to seek the absolute _best_ objective function value.  \n",
    "\n",
    "So what should our objective function be?!  Well, our management objective is to __maximize extracted groundwater__.  So, in this case, the objective function is a simple sum of the decision variable values - easy as!  So how does this look in the PEST interface?  Answer:  prior information equation!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use good'ole `pyemu` to construct these. Note that we assign the name `obj_well` to this equation. We will need that later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.add_pi_equation(future_wpar_names, # parameter names to include in the equation\n",
    "                    pilbl=\"obj_well\",  # the prior information equation name\n",
    "                    obs_group=\"greater_than\") # note the \"greater_\" prefix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.prior_information.equation[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yikes!  That looks like a bunch of junk, but really its a single simple equation summing all of the future water use decision variable values.  The right-hand side value of 0.0 is unused. Now, we tagged this prior info equation with a \"greater_than\" tag for two reasons:  \n",
    "\n",
    "0. to remind us what we want maximize this value and \n",
    "1. for later, more advanced optimization analyses.  \n",
    "\n",
    "PESTPP-OPT allows for “less than” or “greater than” constraints, and are identified using observation group names. If an observation group contains “less than” constraints, then its name must begin with “l_” (that is, the letter “el” followed by an underscore) or “less_”; if an observation group contains “greater than” constraints then its name must begin with “g_” or “greater_”. And recall, prior information equations are also assigned to observation groups!\n",
    "\n",
    "For now, to use the most basic optimization tool in PEST++, we will pass the objective direction directly to the algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.pestpp_options[\"opt_direction\"] = \"max\"\n",
    "pst.pestpp_options[\"opt_objective_function\"] = \"obj_well\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving from DA/UQ to OPT: constraints\n",
    "\n",
    "This is where things get interesting.  If we were to run the optimization now, the algorithm would simply take each decision variable to its upper bound since that is the maximum of the objective function.  But this would obviously not be acceptable because of ecological impacts (the surface-water/groundwater exchange would be not-good!).  So we need to \"constrain\" the optimization problem.  \n",
    "\n",
    "A bit more terminology: a \"feasible\" solution is one where the decision variables yield a simulation result that satisfies all of the _constraints_.  \n",
    "\n",
    "Let's now set up \"model-based\" or observation constraints.  We are going to target the \"incremental\" global water budget SFR components - these represent the flux of groundwater to surface-water.  (Note the sign convention is negative means from groundwater to surface-water.)  So, to maintain ecological flows, we want to keep a (substantially) negative value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = pst.observation_data\n",
    "swgw_obs = obs.loc[obs.obsnme.str.contains(\"inc\") & obs.obsnme.str.contains(\"sfr\"),:]\n",
    "swgw_obs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "swgw_obs.plot(x='totim', y='obsval',figsize=(12,3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that in the second half of the time period the incremental surface flux gets pretty close to 0.0, the point where groundwater stops contributing to surface-water.  So lets form an interesting optimization problem:  the incremental SFR flux must be \"less than\" 0 $\\frac{L^3}{T}$. Meaning we want to make sure that groundwater extraction is __not__ inducing flows from the surface-water to the groundwater system.  We tell the PEST++ optmization tools about these constraints by tagging their observation group name with \"less_than\" and giving them non-zero weight:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get \"future\" swgw_obs names\n",
    "swgw_obs.loc[:,\"totim\"] = swgw_obs.totim.astype(float)\n",
    "swgw_constraint_names = swgw_obs.loc[swgw_obs.totim > 4000,\"obsnme\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whilst we are at it, we need to deactivate all other observations by setting their weight to zero:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[:,\"weight\"] = 0.0 #deactivate all existing non-zero weighted observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now set weights only for the constraint observations, specify the constraint value and assign them to a new group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set weight\n",
    "obs.loc[swgw_constraint_names,\"weight\"] = 1.0 # just non-zero, the value doesnt matter...\n",
    "# set constraint value\n",
    "swgw_rhs = 0.0\n",
    "obs.loc[swgw_constraint_names,\"obsval\"] = swgw_rhs # the constraint right hand side\n",
    "# assign to new obs group\n",
    "obs.loc[swgw_constraint_names,\"obgnme\"] = \"less_than_swgw\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! But there is another problem:  what if there is a minimum flux of groundwater that is needed?  Say for example, that there is a minimum amount of water which _must_ be extracted to ensure municipal supply?  The optimization problem as we have constructed it so far will just turn groundwater extraction rates way down during the dry season to meet ecological constraints, but that might not be enough drinking water - the classic competition for resources problem.  \n",
    "\n",
    "Let's add some more constraints to make sure a minimum amount of groundwater is also produced.  We can do this using the incremental WEL budget component, or we can add additional prior information equations, one for each future stress period.  Its probably easiest to just use the incremental budget obs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wel_obs = obs.loc[obs.obsnme.str.contains(\"inc\") & obs.obsnme.str.contains(\"wel\"),:]\n",
    "wel_obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see an observed value of -2350.0 during the future stress periods. For the sake of the tutorial, let's go with half of that and assume that this value is meaningful.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wel_obs.loc[:,\"totim\"] = wel_obs.totim.astype(float)\n",
    "wel_constraint_names = wel_obs.loc[wel_obs.totim>4000,\"obsnme\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.loc[wel_constraint_names,\"weight\"] = 1.0\n",
    "obs.loc[wel_constraint_names,\"obgnme\"] = \"less_than_wel\" #again, negative means out of groundwater\n",
    "wel_rhs = -2350.0 / 2.0\n",
    "obs.loc[wel_constraint_names,\"obsval\"] = wel_rhs #again, negative means out of groundwater\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moving from DA/UQ to OPT: decision variable increments\n",
    "\n",
    "`PESTPP-OPT` implements a sequential linear programming algorithm.  __Side note:__ the realpython website has a nice introduction to [linear programming](https://realpython.com/linear-programming-python/).\n",
    "\n",
    "The linear programming solve is done using the simplex algorithm (not the Nelder-Mead simplex, the Danzig simplex).  This algorithm requires a \"response\" matrix - a matrix that maps the linear relation between decision variables and constraints.  Sound familiar?  Its exactly the same concept as the Jacobian matrix and we will again rely on finite difference derivatives to fill this matrix - one model run per decision variable.  But, unlike a Jacobian used for parameter estimation/data assimilation, we want to make sure the decision variable perturbation is large enough that we have a representative response at the constraints. So to do this, we will use some of the derivative calculation controls in the `* parameter groups` section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#some pyemu trickery to clean up the pst\n",
    "# rectify_pgroups synchronizes parameter groups section with the parameter data section\n",
    "pst.rectify_pgroups()\n",
    "pst.parameter_groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because our decision variable can reach zero, we need to use the `absolute` increment type. In this case, the increment used for all parameters in the group is supplied as the input variable `derinc`; this increment is added to the current value when calculating derivatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.parameter_groups.loc[\"decvars\",\"inctyp\"] = \"absolute\"\n",
    "pst.parameter_groups.loc[\"decvars\",\"derinc\"] = 2.0 #remember these are multipliers!\n",
    "pst.parameter_groups.loc[\"decvars\",\"derinclb\"] = 2.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run PESTPP-OPT\n",
    "\n",
    "As always, check if the PEST setup runs with the good'ole noptmax=0 run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = 0\n",
    "pst.write(pst_path,version=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.run(\"pestpp-opt freyberg_mf6.pst\",cwd=t_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well, we are now good to deploy pest++opt in parallel. Re-write the control file and let's get cracking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pst.control_data.noptmax = 2\n",
    "pst.write(pst_path,version=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention!\n",
    "\n",
    "You must specify the number which is adequate for ***your*** machine! Make sure to assign an appropriate value for the following `num_workers` variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 8 # update according to your available resources!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then specify the folder in which the PEST manager will run and record outcomes. It should be different from the `t_d` folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_d = os.path.join('master_opt_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell deploys the PEST agents and manager and then starts the run using `pestpp-opt`. Run it by pressing `shift+enter`.\n",
    "\n",
    "If you wish to see the outputs in real-time, switch over to the terminal window (the one which you used to launch the `jupyter notebook`). There you should see `pestpp-opt`'s progress. \n",
    "\n",
    "If you open the tutorial folder, you should also see a bunch of new folders there named `worker_0`, `worker_1`, etc. These are the agent folders. `pyemu` will remove them when PEST finishes running.\n",
    "\n",
    "This run should take a while to complete (depending on the number of workers and the speed of your machine). If you get an error, make sure that your firewall or antivirus software is not blocking `pestpp-opt` from communicating with the agents (this is a common problem!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyemu.os_utils.start_workers(t_d,\"pestpp-opt\",\"freyberg_mf6.pst\",num_workers=num_workers,worker_root=\".\",\n",
    "                           master_dir=m_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing PESTPP-OPT\n",
    "\n",
    "Ok, so now what? Well let's check out the constraints (since we included both the water use and sw-gw exchange fluxes).  Here are the files that might have what we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[f for f in os.listdir(m_d) if f.endswith(\".rei\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wat?! Whats with this \"est\" and \"sim\" stuff?  Well, in PESTPP-OPT, the linear-programming solution yields what it thinks the final constraint values should be, based on the assumed linearity of the response matrix - these are the \"est\"imated constraint values.  But we know that the relation between decision variables and constraints might be non-linear (nah, really?!).  So PESTPP-OPT actually \"sim\"ulates the model one last time with the optimal decision variable values to verify the results. (the \".jcb.rei\" files are the simulation results where the response matrix was calculated).  \n",
    "\n",
    "Lets compare these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "est_df = pyemu.pst_utils.read_resfile(os.path.join(m_d,\"freyberg_mf6.2.est.rei\"))\n",
    "sim_df = pyemu.pst_utils.read_resfile(os.path.join(m_d,\"freyberg_mf6.2.sim.rei\"))\n",
    "constraints = swgw_constraint_names.tolist()\n",
    "constraints.extend(wel_constraint_names)\n",
    "fig,ax = plt.subplots(1,1,figsize=(12,4))\n",
    "sim_df.loc[swgw_constraint_names,\"est\"] = est_df.loc[swgw_constraint_names,\"modelled\"]\n",
    "sim_df.loc[swgw_constraint_names,[\"modelled\",\"est\"]].plot(ax=ax,kind=\"bar\")\n",
    "ax.plot(ax.get_xlim(),[swgw_rhs,swgw_rhs],\"k--\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, so we see that there is some mild nonlinearity but we are still pretty close.  #winning\n",
    "\n",
    "Hackery alert:  now lets visualize the pattern of groundwater use across the future stress periods and plot that with the constraint information. Brace yourselves, the next few cells are code intensive - but mostly so that we can plot up the results. Feel free to jump to the last plot for the important part of the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par_df = pyemu.pst_utils.read_parfile(os.path.join(m_d,\"freyberg_mf6.par\"))\n",
    "par_df.loc[future_wpar_names,:].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wpar = wpar.loc[future_wpar_names,:].copy()\n",
    "wpar.loc[:,\"kij\"] = wpar.apply(lambda x: (x.idx0,x.idx1,x.idx2),axis=1)\n",
    "wpar.loc[:,\"optimal\"] = par_df.loc[wpar.parnme,\"parval1\"]\n",
    "wpar.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inst_vals = wpar.inst.unique()\n",
    "inst_vals.sort()\n",
    "inst_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = [\"r\",\"g\",\"b\",\"c\",\"m\",\"y\",\"0.5\"]\n",
    "vals = {}\n",
    "for inst in inst_vals:\n",
    "    ipar = wpar.loc[wpar.inst==inst,:].copy()\n",
    "    ipar.sort_values(by=\"kij\",inplace=True)\n",
    "    ipar.index = ipar.kij\n",
    "    #ipar.optimal.plot(ax=ax,kind=\"bar\",color=colors)\n",
    "    vals[inst] = ipar.optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df.loc[swgw_constraint_names,[\"modelled\",\"est\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axes = plt.subplots(2,1,figsize=(12,6))\n",
    "colors = [\"r\",\"g\",\"b\",\"c\",\"m\",\"y\",\"0.5\"]\n",
    "df = pd.DataFrame(vals).T\n",
    "df.plot(ax=axes[0],kind=\"bar\",color=colors)\n",
    "axes[0].set_ylim(0,9)\n",
    "nconst = len(wel_constraint_names)-1\n",
    "axes[1].plot(np.arange(nconst),sim_df.loc[wel_constraint_names,\"modelled\"].values[1:],\"b\",lw=1.5)\n",
    "axes[1].plot(axes[1].get_xlim(),[wel_rhs,wel_rhs],\"b--\",lw=3.5)\n",
    "axes[1].fill_between(np.arange(nconst),np.zeros(nconst) + wel_rhs,\n",
    "                     sim_df.loc[wel_constraint_names,\"modelled\"].values[1:],facecolor=\"b\",alpha=0.5)\n",
    "axt = plt.twinx(axes[1])\n",
    "axt.plot(np.arange(nconst),sim_df.loc[swgw_constraint_names,\"modelled\"].values[1:],\"m\",lw=1.5)\n",
    "axt.fill_between(np.arange(nconst),np.zeros(nconst) + swgw_rhs,\n",
    "                     sim_df.loc[swgw_constraint_names,\"modelled\"].values[1:],facecolor=\"m\",alpha=0.5)\n",
    "\n",
    "axt.plot(np.arange(nconst),sim_df.loc[swgw_constraint_names,\"est\"].values[1:],\"g\",lw=1.5)\n",
    "axt.fill_between(np.arange(nconst),np.zeros(nconst) + swgw_rhs,\n",
    "                     sim_df.loc[swgw_constraint_names,\"est\"].values[1:],facecolor=\"g\",alpha=0.5)\n",
    "axes[1].set_xticklabels(inst_vals)\n",
    "axes[0].set_xlim(0,12)\n",
    "axes[1].set_xticks(np.arange(len(wel_constraint_names)-1))\n",
    "axes[1].set_xlim(0,12)\n",
    "axt.plot(axes[1].get_xlim(),[swgw_rhs,swgw_rhs],\"m--\",lw=3.5)\n",
    "axes[1].set_ylim(-10000,0)\n",
    "axt.set_ylim(-700,800)\n",
    "axes[0].set_title(\"Decision Variables\",loc=\"left\")\n",
    "axes[1].set_title(\"Constraints\",loc=\"left\")\n",
    "axes[1].grid()\n",
    "[i.set_color(\"b\") for i in axes[1].get_yticklabels()]\n",
    "[i.set_color(\"m\") for i in axt.get_yticklabels()]\n",
    "lb = axes[1].set_ylabel(\"groundwater extraction rate\")\n",
    "lb.set_color('b')\n",
    "lb = axt.set_ylabel(\"sw-gw exchange rate\")\n",
    "lb.set_color('m')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot in the cell above shows:\n",
    "\n",
    " - (top) Optimal pumping rates at each well during future stress periods. Wells are distinguished by different coloured bars. \n",
    " - (bottom) Total groundwater extraction rate (blue line) and sw-gw exchange rate (purple line). Constraints are identified by the respective blue and purple horizontal dashed-lines. \n",
    "\n",
    "If you can see past the plotting hacks, you'll see that the optimal solution is relatively complex in terms of which extraction wells are active during each stress period. The optimal solution allows for substantially more pumping during stress periods 13 thru 16 (blue shaded region), but then we must back off the extraction rate to meet the sw-gw constraints during stress period 22.  In fact, a little bit of extra sw-gw exchange flux for stress periods 19-22 (magenta fill) is left in the stream - this is likely because the groundwater system memory and an imperfect spatial distribution of extraction wells.  \n",
    "\n",
    "Notice also that in the later stress periods,  extraction is moved to wells located in the northern portion of the domain (smaller \"j\" values in the k-i-j info; see top plot)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next notebook, we will move beyond deterministic/risk neutral optimization to including posterior parameter uncertainties in the optimization...\n",
    "\n",
    "If you are interested in increasing the complexity of this optimization problem, try experimenting with requiring more sw-gw exchange (more negative than 0) and/or requiring more groundwater extraction (more negative than -2350.0).  You will soon see \"infeasible\" in the .rec file, meaning there is not a combination of extraction well rates that can simultaneously satisfy ecological and economic needs..."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
